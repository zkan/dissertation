\setlength{\footskip}{8mm}

\chapter{Introduction} 

\textit{This dissertation explores the possibilities and develops
algorithms for modeling human behaviors and detecting anomalies
without requiring large databases of training data. In this chapter, I
discuss the background \DIFaddbegin \DIFadd{of, }\DIFaddend and motivation \DIFdelbegin \DIFdel{of }\DIFdelend \DIFaddbegin \DIFadd{for }\DIFaddend my work\DIFaddbegin \DIFadd{. Additionally}\DIFaddend , 
\DIFaddbegin \DIFadd{I }\DIFaddend review real-world surveillance systems, present the contributions of 
the work, and provide an outline of this dissertation.}

\section{Background and Motivation}

Due to the increase in demand for video surveillance in public areas,
video surveillance is becoming ubiquitous in our lives. It becomes
increasingly important for preventing and responding to \DIFdelbegin \DIFdel{terrorist }\DIFdelend \DIFaddbegin \DIFadd{terroristic 
threats }\DIFaddend and other criminal activities. However, the resulting proliferation of
surveillance cameras is making it increasingly difficult to monitor
all channels continuously. Human monitoring is therefore becoming
increasingly expensive and ineffective as the torrent of video data
increases. For instance, in a CCTV monitoring room (see
Figure \ref{fig:monitoring}), security operators are required to
monitor 24 hours a day and be ready to take action when an alarm
occurs. Security will be enhanced if there is an intelligent
surveillance system able to perform filtering, \DIFdelbegin \DIFdel{archiving }\DIFdelend \DIFaddbegin \DIFadd{archive }\DIFaddend ``normal''
events, and automatically \DIFdelbegin \DIFdel{raising }\DIFdelend \DIFaddbegin \DIFadd{raise }\DIFaddend alarms for possible ``abnormal''
events or presenting such events to human security personnel for
consideration as a security threat. The problems to consider in a
surveillance system include pedestrian detection and tracking,
unattended object detection, human behavior modeling, and anomaly
detection.

\begin{figure}[t]
    \centering
    \includegraphics[width=5in]{figures/monitoring}
    \caption[CCTV monitoring room.]{\small CCTV monitoring
        room. Reprinted from the Twenty First Security Web site
        (\url{http://www.twentyfirstsecurity.com.au/}).}
    \label{fig:monitoring}
\end{figure}

Human behavior understanding is one of the \DIFdelbegin \DIFdel{key components }\DIFdelend \DIFaddbegin \DIFadd{most intricate and complex facets }\DIFaddend of
intelligent video surveillance. 
\DIFdelbegin \DIFdel{However, the }\DIFdelend \DIFaddbegin \DIFadd{Clearly, behavioral understanding can be problematic because it requires 
considerable time to study each individual subject, and often cannot 
predict ``one-time'' malicious behavior before it happens.
The }\DIFaddend problem is difficult and
remains unsolved, due to the wide range of activities possible in any
given context and the large amount of variability within any
particular activity.

One limitation of much of the existing work is that it learns in batch
mode and creates separate models, which remain static once trained,
for each distinct class of behavior. It may have an advantage in
explaining data that are well-defined, but it needs sufficiently large
samples of behavior patterns before training the system. Another
limitation is that the number of ``normal'' behavior patterns needs to
be known beforehand because we cannot learn a model for ``abnormal''
behavior that is rare and diverse. Therefore, we must instead detect
deviations from typical behavior.

The ambiguity of human behaviors makes the problem more challenging
since it is scene-dependent and can change over time. In particular, a
behavior considered normal in one context might be considered unusual
in another context depending on the type of behavior and where and
when it is observed. The characteristics of typical behavior also vary
from scene to scene.

Many researchers have attempted to build surveillance systems able to
interpret and understand human behaviors. However, most of the work
learns behaviors in an offline fashion and keeps the model static once
trained. This is impractical for real-time surveillance applications,
since offline training requires a great deal of computational time and
resources. In addition, the number of behaviors needs to be known
beforehand. We therefore need to find a way to initially recognize and
model each of the common behavior groups in a particular scene as well
as to incrementally learn scene-specific models as new behavior is
observed.

Many open source and commercial video surveillance products are 
available. Most of the products do not implement any intelligent
features; therefore, they cannot learn and understand the events
occurring in a scene. Moreover, a great deal of configuration must be done
before a user can deploy the system to operate in a real situation.
For instance, a user may need to define restricted zones or rules
for a specific scene.

Three main challenges for human behavior understanding and anomaly
detection are as follows.

\begin{enumerate}
    \item It is impractical to store all data in a system; therefore, we
        need an efficient approach that learns scene-specific statistical
        models of human behavior without requiring storage of large
        databases of training data.
    \item Real human behavior is sometimes ambiguous; therefore, we need to 
        keep humans such as security personnel in the loop to interpret it.
    \item Unusual behavior is rare and diverse, and it is also impractical 
        to acquire sufficient data for a good model for it; therefore, we 
        need to detect deviations from typical behavior instead.
\end{enumerate}

In this dissertation, we propose to explore, implement, and evaluate
an efficient method for automatic identification of suspicious
behavior in video surveillance data that incrementally learns
scene-specific statistical models of human behavior without requiring
storage of large databases of training data. The method is based on
hidden Markov models (HMMs) with sufficient statistics and an optimal
threshold on the likelihood of an event according to the human
behavior model.  We begin by building an initial set of models
explaining the behaviors occurring in a small bootstrap data set. The
bootstrap procedure partitions the bootstrap set into clusters then
assigns new observation sequences to clusters based on statistical
tests of HMM log likelihood scores. Cluster-specific likelihood
thresholds are learned rather than set arbitrarily. After
bootstrapping, each new sequence is used to incrementally update the
sufficient statistics of the HMM it is assigned to. Our method is an
effective solution to the problem of inducing scene-specific
statistical models useful for bringing suspicious behavior to the
attention of human security personnel.

\section{Review of \DIFdelbegin \DIFdel{Real-World }\DIFdelend \DIFaddbegin \DIFadd{State of the Art in }\DIFaddend Surveillance Systems}

We divide this section into \DIFaddbegin \DIFadd{two parts. The first part describes the 
review of }\DIFaddend open source and commercial products. \DIFaddbegin \DIFadd{The second part describes 
the review of the state of the art in surveillance systems.
}\DIFaddend 

\subsection{Open Source \DIFaddbegin \DIFadd{and Commercial }\DIFaddend Products}

ZoneMinder (ZM; Coombes, 2007)\nocite{zoneminder} is an open source
video surveillance system for Linux. It has been released under the
terms of the GNU general public license (GPL). ZM supports both IP
cameras and USB cameras. Figure \ref{fig:zm-webcam} shows an example
of a scene captured by an IP camera and a USB camera. The system
consists of many independent modules including motion detection.  Each
component is designed to use as few resources as possible, maximizing
the efficiency of the machine. It provides a PHP-based Web interface
that allows us to control the cameras and monitor a scene from
anywhere. Besides controlling and monitoring, we can also review,
archive, or delete the events through its Web interface.

\begin{figure}[t]
  \begin{center}
    \subfloat[]{\includegraphics[scale=0.6]{figures/zm-webcam01.jpg}
    \label{fig:zm-webcam01}}
    \hspace{0.1in}
    \subfloat[]{\includegraphics[scale=0.6]{figures/zm-webcam02.jpg}
    \label{fig:zm-webcam02}}
  \end{center}
  \caption[Example of a scene captured by ZoneMinder.]{\small Example
    of a scene captured by (a) an IP camera and (b) a USB camera from
    ZoneMinder.}
  \label{fig:zm-webcam}
\end{figure}

SecureCam \shortcite{bedecs09securecam} is \DIFdelbegin \DIFdel{a }\DIFdelend \DIFaddbegin \DIFadd{an }\DIFaddend open source software
\DIFdelbegin \DIFdel{for
}\DIFdelend \DIFaddbegin \DIFadd{project for the }\DIFaddend Windows platform providing a friendly user interface as
shown in Figure \ref{fig:securecam}. Similar to ZoneMinder, SecureCame
supports multiple cameras and provides a few simple and fast
algorithms such as motion detection. It has e-mail and sound
notification features, and it also allows users to record video for
later review.

\begin{figure}[t]
  \begin{center}
    \includegraphics[width=4in]{figures/securecam.jpg}
    \caption[Screen shot of SecureCam.]{\small Screen shot of
      SecureCam. Reprinted from the SecureCam Web site
      (\url{http://sourceforge.net/projects/securecam/}).}
    \label{fig:securecam}
  \end{center}
\end{figure}

\DIFdelbegin \subsection{\DIFdel{Commercial Products}}
%DIFAUXCMD
\addtocounter{subsection}{-1}%DIFAUXCMD
%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend Vitamin D Video \shortcite{vitamind} is a commercial video
surveillance system. It supports USB webcams and network cameras and
provides advanced features such as creating rules for specific events.
For example, the user could create a rule to record a clip only when a
person opens \DIFdelbegin \DIFdel{the }\DIFdelend \DIFaddbegin \DIFadd{a }\DIFaddend door, or the user could create a rule to notify via
email when the system senses some movement in a defined region. The
system also allows users to monitor a scene and to search for videos
of interest.  Figure \ref{fig:vitamind} shows a screen shot of the
software.

\begin{figure}[t]
  \begin{center}
    \includegraphics[width=4in]{figures/vitamind.jpg}
    \caption[Screen shot of Vitamin D Video.]{\small Screen shot of
      Vitamin D Video. Reprinted from the Vitamin D Video Web site
      (\url{http://www.vitamindinc.com/}).}
    \label{fig:vitamind}
  \end{center}
\end{figure}

It is interesting that Vitamin D Video does not use motion detection,
but rather uses people detection. It uses hierarchical temporal memory
(HTM; Hawkins, 2007)\nocite{jeff07htm} to detect people. This
algorithm attempts to apply the concept of how the brain recognizes a
\DIFdelbegin \DIFdel{person}\DIFdelend \DIFaddbegin \DIFadd{human being}\DIFaddend .

Video Analytics \shortcite{dvtel} is a video surveillance software
package that includes many different modules.  Sample modules are
intrusion detection, unattended baggage detection, object removal
detection, autonomous pan-tilt-zoom (PTZ) tracking, stopped vehicle
detection, loitering detection, and camera tampering
detection. However, some modules such as intrusion detection do not
have any intelligent features.

SuperTrack \shortcite{supertrack} is an intelligent video surveillance
system. SuperTrack is designed for automatically analyzing and
monitoring events without the need for human attention and
interaction. This system provides automatic object detection, abnormal
behavior detection, tracking, and so on. However, it requires the user
to configure and maintain a set of alarm trigger rules in
advance. SuperTrack also supports various types of cameras such as USB
cameras and network cameras.  Figure \ref{fig:supertrack} shows a
screen shot of the system.

\begin{figure}[t]
  \begin{center}
    \includegraphics[width=3in]{figures/supertrack.jpg}
    \caption[Screen shot of SuperTrack.]{\small Screen shot of
      SuperTrack. Reprinted from the Stratech Web site
      (\url{http://www.stratechsystems.com/iv_supertrack.asp}).}
    \label{fig:supertrack}
  \end{center}
\end{figure}

\DIFdelbegin \subsection{\DIFdel{Summary}}
%DIFAUXCMD
\addtocounter{subsection}{-1}%DIFAUXCMD
\DIFdelend \DIFaddbegin \DIFadd{The review on open source and commercial video surveillance 
products makes us realize the importance of and demand for human 
behavior modeling and anomaly detection. 
}\DIFaddend 

\DIFdelbegin \DIFdel{Many }\DIFdelend \DIFaddbegin \subsection{\DIFadd{State of the Art Systems}}

\DIFadd{In general, }\DIFaddend open source and commercial video surveillance products \DIFdelbegin \DIFdel{are
available; however, most of them }\DIFdelend \DIFaddbegin \DIFadd{lag
behind state-of-the-art systems that are currently in development in
academia. Even though there are a vast number of different systems to
choose from, most }\DIFaddend do not provide \DIFdelbegin \DIFdel{intelligent
features}\DIFdelend \DIFaddbegin \DIFadd{the most intelligent features that
are available}\DIFaddend . Therefore, they cannot understand the events occurring
in a scene or learn human activities. In addition, users are required
to provide a great deal of configuration parameters before they can
deploy \DIFdelbegin \DIFdel{the }\DIFdelend \DIFaddbegin \DIFadd{a }\DIFaddend system to operate in real-world situations. For instance, in
\DIFdelbegin \DIFdel{all of the }\DIFdelend \DIFaddbegin \DIFadd{most commercial and open source }\DIFaddend systems, restricted zones or rules for
a scene need to be defined \DIFdelbegin \DIFdel{beforehand}\DIFdelend \DIFaddbegin \DIFadd{for the system to operate optimally}\DIFaddend .

\DIFdelbegin \DIFdel{This review on open source and commercial video surveillance products
makes us realize the importance of and demand for human behavior
modeling and anomaly detection.
Nowadays, in order to solve real-world
problems, research needs to focus on both academic issues and the
commercial market. }\DIFdelend %DIF > Studying only the review of these products or vendor claims is 
%DIF > not enough. A more in-depth review of the state-of-the-art in 
%DIF > surveillance systems is highly recommended. 

\DIFaddbegin \DIFadd{There have been a number of significant research advances with novel
methodologies for visual surveillance in recent years, including
automatic human activity interpretation and wide-area surveillance to
reduce maintenance costs and human interaction and the propensity for
human error.
}

%DIF > To build such an intelligent surveillance system, 
%DIF > research on motion detection, object tracking 
%DIF > and behavior understanding is indispensable.

%DIF > Motion detection finds moving objects in an input video. 
%DIF > With the rapid proliferation of surveillance cameras, motion 
%DIF > detection becomes an important component of surveillance systems. 
%DIF > Using a simple technique such as frame-by-frame subtraction as 
%DIF > commonly used in open source or commercial products is not 
%DIF > comprehensive enough. More advanced techniques such as 
%DIF > background subtraction \shortcite{wren97pfinder,stauffer99background,poppe07background} 
%DIF > will provide a more robust and comprehensive system.
%DIF > 
%DIF > Object tracking ...
%DIF > 
%DIF > Behavior understanding ...

\shortciteA{zhong04detection} \DIFadd{use a clustering-based similarity approach 
for detecting abnormal activity in video. They evaluate the 
approach on several real world surveillance videos such as a video from 
surveillance camera overlooking a road adjacent to a fenced facility. 
The experimental results are shown in Figure \ref{fig:zhong-work}.
}

\begin{figure}[t]
    \centering \includegraphics[width=5.5in]{figures/zhong-road-surveillance-video.png} \caption[Zhong
    et al.'s experimental results on road surveillance video.]{\DIFaddFL{Zhong
    et al.'s experimental results on road surveillance video.  Usual
    events consist of cars moving along the road. Correctly detected
    unusual events include: (A) cars pulling off the road, (B) cars
    stopping and backing up, (C) cars making U-turns and people
    walking on the road. Undetected unusual events include: (D) cars
    stopping on the far end, due to coarseness of the spatial
    features. Reprinted from Zhong et al.}\
    \DIFaddFL{(2004).}}  \label{fig:zhong-work}
\end{figure}

\shortciteA{georis04video} \DIFadd{build a real-time bank agency monitoring system. 
The scenarios are modeled 
by domain expert knowledge. End-user feedback is collected to improve the 
scenario models. Figure \ref{fig:georis-work} shows a scenario of a coordinated 
bank attack of multiple robbers.
}

\begin{figure}[t]
    \centering
    \includegraphics[width=5.5in]{figures/georis-bank-attack.png}
    \caption[Example video of a simulated bank attack.]
        {\DIFaddFL{Example video of a simulated bank attack. (a) Person enters the bank. 
        (b) Robber is identified to be an outsider. Robber is entering the 
        bank safe. (c) A customer leaves the bank. (d) Robber leaves the bank. 
        Reprinted from Turaga et al.}\ \DIFaddFL{(2008).}\mbox{%DIFAUXCMD
\nocite{turaga08survey}
}%DIFAUXCMD
}
    \label{fig:georis-work}
\end{figure}

\shortciteA{vaswani05activity} \DIFadd{use a statistical model such as a 
continuous-state hidden Markov model (HMM) for the configuration of 
a set of landmark shape dynamics in an activity. They identify an 
abnormal activity defined 
as a change in the shape activity model. Their approach is used in 
an airport scenario with people deplaning and moving toward the 
terminal. Figure \ref{fig:vaswani-work} shows an example of people 
deplaning.
}

\begin{figure}[t]
    \centering
    \subfloat[]{\includegraphics[width=2in]{figures/vaswani-normal-activity.png}}
    \DIFaddFL{\hspace{0.03in}
    }\subfloat[]{\includegraphics[width=2in]{figures/vaswani-abnormal-activity.png}}
    \caption[Vaswani et al.'s experimental results on an airport scenario.]
        {\small \DIFaddFL{Vaswani et al.'s 
        experimental results on an airport scenario. (a) A ``normal activity'' 
        frame with 4 people. 
        (b) Abnormality introduced by making one person walk-away in an 
        abnormal direction. Reprinted from Vaswani et al.}\ \DIFaddFL{(2005)}}
    \label{fig:vaswani-work}
\end{figure}

\DIFaddend \section{Contributions}

The contributions of this dissertation are as follows.

\begin{enumerate}
  \item We propose an intelligent video surveillance system that is
    practical and fairly close to the ideal surveillance system, which
    should monitor \DIFdelbegin \DIFdel{and automatically raise }\DIFdelend \DIFaddbegin \DIFadd{activity and automatically trigger }\DIFaddend alarms to security
    personnel;

  \item We develop an algorithm for extracting and tracking multiple 
    moving foreground blobs in a scene using an appearance model;

  \item We propose a shadow detection method that uses a simple
    maximum likelihood classification approach based on color
    information;

  \item We propose a new method for clustering human behaviors that 
    is suitable for bootstrapping an anomaly detection module for 
    intelligent video surveillance systems;

  \item We propose and develop a new and effective algorithm for
    semi-supervised learning of common human behaviors and detect 
    anomalies in video sequences;

  \item We introduce a new and more accurate algorithm for
    incrementally profiling human behaviors in video sequences without
    requiring storage of large databases of training data;

  \item We provide the source code and datasets
    online\footnote{See \url{http://www.kanouivirach.com/#downloads}.}
    for researchers interested in evaluating or extending our work.
\end{enumerate}

\subsection{List of Publications}

We provide a list of publications as part of this dissertation. We
also include the list of works currently under review and preparation
for submission.

\subsection*{Published Works}

\begin{itemize}
  \renewcommand\labelitemi{--} 

  \item \DIFaddbegin {\bf{Extracting the Object from the Shadows: Maximum
    Likelihood Object/Shadow Discrimination}}\\ \DIFadd{Kan Ouivirach and
    Matthew N.}\ \DIFadd{Dailey}\\ \textit{\DIFadd{International Conference on
    Electrical Engineering/Electronics Computer Telecommunications and
    Information Technology (ECTI-CON)}}\DIFadd{, pages 1--5, 2013}\\ 
    \DIFadd{Publisher: IEEE Computer Society}\\ \DIFadd{Included in 
    Chapter~\ref{ch:shadow}
}

  \item \DIFaddend \textbf{Clustering Human Behaviors with Dynamic Time Warping
    and Hidden Markov Models for a Video Surveillance
    System}\nocite{kan10clustering}\\ Kan Ouivirach and Matthew N.\
    Dailey\\ \textit{International Conference on Electrical
    Engineering/Electronics Computer Telecommunications and
    Information Technology (ECTI-CON)}, pages 884--888, 2010\\
    Publisher: IEEE Computer Society\\ Included in
    Chapter~\ref{ch:clustering}\\

  \item \textbf{Automatic Suspicious Behavior Detection from a Small
    Bootstrap Set}\nocite{kan12detection}\\ Kan Ouivirach, Shashi
    Gharti, and Matthew N.\ Dailey\\ \textit{International Conference
    on Computer Vision Theory and Applications (VISAPP)}, volume 1,
    pages 655--658, 2012\\ Publisher: Springer-Verlag\\ Included in
    Chapter~\ref{ch:batch}\\

  \item \textbf{Incremental Behavior Modeling and Suspicious Activity
    Detection}\nocite{kan13incremental}\\ Kan Ouivirach, Shashi
    Gharti, and Matthew N.\ Dailey\\ \textit{Pattern Recognition},
    46(3): 671--680, 2013\\ Publisher: Elsevier\\ Included in
    Chapter~\ref{ch:incremental}
  \DIFdelbegin %DIFDELCMD < 

%DIFDELCMD < \end{itemize}
%DIFDELCMD < 

%DIFDELCMD < %%%
\subsection*{\DIFdel{Manuscripts Currently under Review}}
%DIFAUXCMD
%DIFDELCMD < 

%DIFDELCMD < \begin{itemize}
%DIFDELCMD <   \renewcommand\labelitemi{--}
%DIFDELCMD < 

%DIFDELCMD <   \item {\bf{Extracting the Object from the Shadows: Maximum
%DIFDELCMD <     Likelihood Object/Shadow Discrimination}}\\ %%%
\DIFdel{Kan Ouivirach and
    Matthew N.}%DIFDELCMD < \ %%%
\DIFdel{Dailey}%DIFDELCMD < \\ %%%
\textit{\DIFdel{International Conference on
    Electrical Engineering/Electronics Computer Telecommunications and
    Information Technology (ECTI-CON)}}%DIFAUXCMD
\DIFdel{, 2013}%DIFDELCMD < \\ %%%
\DIFdel{Publisher: IEEE
    Computer Society}%DIFDELCMD < \\ %%%
\DIFdel{Included in Chapter~\ref{ch:shadow}
}\DIFdelend 

\end{itemize}

\subsection*{Manuscripts Currently in Preparation}

\begin{itemize}
  \renewcommand\labelitemi{--}

  \item {\bf{Incorporating Geometric and Shadow Region Shape
    Information for Shadow Detection}}\\ Kan Ouivirach and Matthew N.\
    Dailey\\ To be submitted in \textit{International Conference on
    Computer Vision and Pattern Recognition (CVPR)}, 2013\\ Publisher:
    IEEE Computer Society

\end{itemize}

\section{Organization of Dissertation}

I organize the rest of this dissertation as follows.

In Chapter \ref{ch:blobanalysis}, I describe our blob-based motion
analysis methods including blob extraction and appearance-based blob
tracking.

In Chapter \ref{ch:shadow}, I present a new method for detecting
shadows using a simple maximum likelihood classification method based
on color information.

In Chapter \ref{ch:clustering}, I propose a new method for clustering
behaviors in a scene.

In Chapter \ref{ch:batch}, I present an automatic suspicious behavior
detection method that uses a small bootstrap set.

In Chapter \ref{ch:incremental}, I describe our extension of the
suspicious behavior detection approach for incremental learning in
which security personnel feedback is incorporated.

Finally, in Chapter \ref{ch:conclusion}, I conclude and discuss the
possible further extensions of my dissertation.

\FloatBarrier


% --- Maybe use later ---

%(see Figure \ref{fig:zm-console}) 
%\begin{figure}[t]
%  \begin{center}
%    \includegraphics[width=4.5in]{figures/zm-console.jpg}
%    \caption{ZM Console} 
%    \label{fig:zm-console}
%  \end{center}
%\end{figure}

%ZM has three main modules. The first is the ZM Capture (ZMC) module
%whose job is to capture video frames from a video device as quickly as
%possible. The second is the ZM Analysis (ZMA) module, which performs
%video analysis. It finds the captured frames and checks whether the
%detected motion should generate an alarm or not. The last is the ZM
%Frame (ZMF) module. It is an optional module for writing the captured
%frames to file system. This module could potentially reduce the
%workload of ZMA, so ZMA can do more analysis work. If ZMF is not
%enabled, ZMA will write captured frames to file system instead.

%The core of ZM supports capturing and analyzing images. It also
%provides a configurable set of parameters (see
%Figure \ref{fig:zm-option}). ZM allows us to define ``zones'' for each
%camera and vary the sensitivity and functionality (see
%Figure \ref{fig:zm-webcam01-zones}
%and \ref{fig:zm-webcam01-zones-define}). Therefore, we can eliminate
%unnecessary regions and set the different thresholds for each zone. ZM
%also provides a motion detection feature for detecting changes in a
%scene and setting an alarm based on the user-defined threshold.

%\begin{figure}[t]
%  \begin{center}
%    \includegraphics[width=4.5in]{figures/zm-options.jpg}
%    \caption{ZM Options}
%    \label{fig:zm-option}
%  \end{center}
%\end{figure}

%\begin{figure}[t]
%  \begin{center}
%    \subfloat[]{\includegraphics[scale=0.5]{figures/zm-webcam01-zones.jpg}\label{fig:zm-webcam01-zones}}
%    \hspace{0.1in}
%    \subfloat[]{\includegraphics[scale=0.5]{figures/zm-webcam01-zones-define.jpg}\label{fig:zm-webcam01-zones-define}}
%  \end{center}  
%  \caption[Example of zone defined in ZoneMinder]{Example of (a) zone
%  defined and (b) configuring a zone in ZoneMinder.}
%  \label{fig:zm-webcam-zones}
%\end{figure}

%Here I review only the intrusion detection module.  
%The intrusion detection module automatically detects prohibited
%intrusion behaviors while ignoring distractions that cause false
%alarms, like small animals, swaying branches,
%etc. Figure \ref{fig:intrusion-detection} shows a screen shot of the
%result from this module. This module can be used on stationary cameras
%as well as on PTZ cameras. There are two modes which are Regional
%Entrance and Tripwire. The first mode provides a security alarm when
%the system detects a person or vehicle moving within a prohibited
%area. The second mode provides a security alarm when a person or
%vehicle breaks through a demarcation line. User can configure this
%mode to prohibit any crossover or to allow movement in a single
%direction.

%\begin{figure}[t]
%  \begin{center}
%    \includegraphics[width=3in]{figures/intrusion-detection.png}
%     \caption[Screen shot of DVTel's intrusion detection
%     module]{Screen shot of DVTel's intrusion detection
%     module. Captured from the video demonstration on DVTel's Web
%     site.}
%    \label{fig:intrusion-detection}
%  \end{center}
%\end{figure}

%For example, it has the knowledge that a head contains two
%eyes and a mouth; so, if either an eye or mouth is detected, it will
%assume that there is a head at that position. Vitamin D Video trained
%a learning network with several hundred videos of humans. Also,
%examples of vehicles and animals not people are trained. As a result,
%Vitamin D Video can tolerate to real world problems.
